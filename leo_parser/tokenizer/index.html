<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="generator" content="rustdoc"><meta name="description" content="The tokenizer to convert Leo code text into tokens."><title>leo_parser::tokenizer - Rust</title><script>if(window.location.protocol!=="file:")document.head.insertAdjacentHTML("beforeend","SourceSerif4-Regular-6b053e98.ttf.woff2,FiraSans-Italic-81dc35de.woff2,FiraSans-Regular-0fe48ade.woff2,FiraSans-MediumItalic-ccf7e434.woff2,FiraSans-Medium-e1aa3f0a.woff2,SourceCodePro-Regular-8badfe75.ttf.woff2,SourceCodePro-Semibold-aa29a496.ttf.woff2".split(",").map(f=>`<link rel="preload" as="font" type="font/woff2" crossorigin href="../../static.files/${f}">`).join(""))</script><link rel="stylesheet" href="../../static.files/normalize-9960930a.css"><link rel="stylesheet" href="../../static.files/rustdoc-84e720fa.css"><meta name="rustdoc-vars" data-root-path="../../" data-static-root-path="../../static.files/" data-current-crate="leo_parser" data-themes="" data-resource-suffix="" data-rustdoc-version="1.89.0 (29483883e 2025-08-04)" data-channel="1.89.0" data-search-js="search-92309212.js" data-settings-js="settings-5514c975.js" ><script src="../../static.files/storage-4e99c027.js"></script><script defer src="../sidebar-items.js"></script><script defer src="../../static.files/main-fd3af306.js"></script><noscript><link rel="stylesheet" href="../../static.files/noscript-32bb7600.css"></noscript><link rel="alternate icon" type="image/png" href="../../static.files/favicon-32x32-6580c154.png"><link rel="icon" type="image/svg+xml" href="../../static.files/favicon-044be391.svg"></head><body class="rustdoc mod"><!--[if lte IE 11]><div class="warning">This old browser is unsupported and will most likely display funky things.</div><![endif]--><nav class="mobile-topbar"><button class="sidebar-menu-toggle" title="show sidebar"></button></nav><nav class="sidebar"><div class="sidebar-crate"><h2><a href="../../leo_parser/index.html">leo_<wbr>parser</a><span class="version">3.1.0</span></h2></div><div class="sidebar-elems"><section id="rustdoc-toc"><h2 class="location"><a href="#">Module tokenizer</a></h2><h3><a href="#reexports">Module Items</a></h3><ul class="block"><li><a href="#reexports" title="Re-exports">Re-exports</a></li><li><a href="#modules" title="Modules">Modules</a></li><li><a href="#functions" title="Functions">Functions</a></li></ul></section><div id="rustdoc-modnav"><h2 class="in-crate"><a href="../index.html">In crate leo_<wbr>parser</a></h2></div></div></nav><div class="sidebar-resizer" title="Drag to resize sidebar"></div><main><div class="width-limiter"><rustdoc-search></rustdoc-search><section id="main-content" class="content"><div class="main-heading"><div class="rustdoc-breadcrumbs"><a href="../index.html">leo_parser</a></div><h1>Module <span>tokenizer</span><button id="copy-path" title="Copy item path to clipboard">Copy item path</button></h1><rustdoc-toolbar></rustdoc-toolbar><span class="sub-heading"><a class="src" href="../../src/leo_parser/tokenizer/mod.rs.html#17-207">Source</a> </span></div><details class="toggle top-doc" open><summary class="hideme"><span>Expand description</span></summary><div class="docblock"><p>The tokenizer to convert Leo code text into tokens.</p>
<p>This module contains the <a href="fn.tokenize.html" title="fn leo_parser::tokenizer::tokenize"><code>tokenize()</code></a> function, which breaks down string text into tokens,
optionally separated by whitespace.</p>
</div></details><h2 id="reexports" class="section-header">Re-exports<a href="#reexports" class="anchor">Â§</a></h2><dl class="item-table reexports"><dt id="reexport.KEYWORD_TOKENS"><code>pub use self::token::<a class="constant" href="../constant.KEYWORD_TOKENS.html" title="constant leo_parser::KEYWORD_TOKENS">KEYWORD_TOKENS</a>;</code></dt></dl><h2 id="modules" class="section-header">Modules<a href="#modules" class="anchor">Â§</a></h2><dl class="item-table"><dt><a class="mod" href="lexer/index.html" title="mod leo_parser::tokenizer::lexer">lexer</a><span title="Restricted Visibility">&nbsp;ðŸ”’</span> </dt><dt><a class="mod" href="token/index.html" title="mod leo_parser::tokenizer::token">token</a><span title="Restricted Visibility">&nbsp;ðŸ”’</span> </dt></dl><h2 id="functions" class="section-header">Functions<a href="#functions" class="anchor">Â§</a></h2><dl class="item-table"><dt><a class="fn" href="fn.tokenize.html" title="fn leo_parser::tokenizer::tokenize">tokenize</a><span title="Restricted Visibility">&nbsp;ðŸ”’</span> </dt><dd>Creates a new vector of spanned tokens from a given file path and source code text.</dd><dt><a class="fn" href="fn.tokenize_iter.html" title="fn leo_parser::tokenizer::tokenize_iter">tokenize_<wbr>iter</a><span title="Restricted Visibility">&nbsp;ðŸ”’</span> </dt><dd>Yields spanned tokens from the given source code text.</dd></dl></section></div></main></body></html>