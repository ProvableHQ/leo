<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="generator" content="rustdoc"><meta name="description" content="Source of the Rust file `compiler/parser/src/tokenizer/mod.rs`."><title>mod.rs - source</title><script>if(window.location.protocol!=="file:")document.head.insertAdjacentHTML("beforeend","SourceSerif4-Regular-6b053e98.ttf.woff2,FiraSans-Italic-81dc35de.woff2,FiraSans-Regular-0fe48ade.woff2,FiraSans-MediumItalic-ccf7e434.woff2,FiraSans-Medium-e1aa3f0a.woff2,SourceCodePro-Regular-8badfe75.ttf.woff2,SourceCodePro-Semibold-aa29a496.ttf.woff2".split(",").map(f=>`<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../static.files/${f}">`).join(""))</script><link rel="stylesheet" href="../../../static.files/normalize-9960930a.css"><link rel="stylesheet" href="../../../static.files/rustdoc-6c3ea77c.css"><meta name="rustdoc-vars" data-root-path="../../../" data-static-root-path="../../../static.files/" data-current-crate="leo_parser" data-themes="" data-resource-suffix="" data-rustdoc-version="1.86.0 (05f9846f8 2025-03-31)" data-channel="1.86.0" data-search-js="search-581efc7a.js" data-settings-js="settings-6dad6058.js" ><script src="../../../static.files/storage-3a5871a4.js"></script><script defer src="../../../static.files/src-script-b8d3f215.js"></script><script defer src="../../../src-files.js"></script><script defer src="../../../static.files/main-4d63596a.js"></script><noscript><link rel="stylesheet" href="../../../static.files/noscript-893ab5e7.css"></noscript><link rel="alternate icon" type="image/png" href="../../../static.files/favicon-32x32-6580c154.png"><link rel="icon" type="image/svg+xml" href="../../../static.files/favicon-044be391.svg"></head><body class="rustdoc src"><!--[if lte IE 11]><div class="warning">This old browser is unsupported and will most likely display funky things.</div><![endif]--><nav class="sidebar"><div class="src-sidebar-title"><h2>Files</h2></div></nav><div class="sidebar-resizer"></div><main><rustdoc-search></rustdoc-search><section id="main-content" class="content"><div class="main-heading"><h1><div class="sub-heading">leo_parser/tokenizer/</div>mod.rs</h1><rustdoc-toolbar></rustdoc-toolbar></div><div class="example-wrap digits-3"><pre class="rust"><code><a href=#1 id=1 data-nosnippet>1</a><span class="comment">// Copyright (C) 2019-2025 Provable Inc.
<a href=#2 id=2 data-nosnippet>2</a>// This file is part of the Leo library.
<a href=#3 id=3 data-nosnippet>3</a>
<a href=#4 id=4 data-nosnippet>4</a>// The Leo library is free software: you can redistribute it and/or modify
<a href=#5 id=5 data-nosnippet>5</a>// it under the terms of the GNU General Public License as published by
<a href=#6 id=6 data-nosnippet>6</a>// the Free Software Foundation, either version 3 of the License, or
<a href=#7 id=7 data-nosnippet>7</a>// (at your option) any later version.
<a href=#8 id=8 data-nosnippet>8</a>
<a href=#9 id=9 data-nosnippet>9</a>// The Leo library is distributed in the hope that it will be useful,
<a href=#10 id=10 data-nosnippet>10</a>// but WITHOUT ANY WARRANTY; without even the implied warranty of
<a href=#11 id=11 data-nosnippet>11</a>// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
<a href=#12 id=12 data-nosnippet>12</a>// GNU General Public License for more details.
<a href=#13 id=13 data-nosnippet>13</a>
<a href=#14 id=14 data-nosnippet>14</a>// You should have received a copy of the GNU General Public License
<a href=#15 id=15 data-nosnippet>15</a>// along with the Leo library. If not, see &lt;https://www.gnu.org/licenses/&gt;.
<a href=#16 id=16 data-nosnippet>16</a>
<a href=#17 id=17 data-nosnippet>17</a></span><span class="doccomment">//! The tokenizer to convert Leo code text into tokens.
<a href=#18 id=18 data-nosnippet>18</a>//!
<a href=#19 id=19 data-nosnippet>19</a>//! This module contains the [`tokenize()`] function, which breaks down string text into tokens,
<a href=#20 id=20 data-nosnippet>20</a>//! optionally separated by whitespace.
<a href=#21 id=21 data-nosnippet>21</a>
<a href=#22 id=22 data-nosnippet>22</a></span><span class="kw">pub</span>(<span class="kw">crate</span>) <span class="kw">mod </span>token;
<a href=#23 id=23 data-nosnippet>23</a>
<a href=#24 id=24 data-nosnippet>24</a><span class="kw">pub use </span><span class="self">self</span>::token::KEYWORD_TOKENS;
<a href=#25 id=25 data-nosnippet>25</a><span class="kw">pub</span>(<span class="kw">crate</span>) <span class="kw">use </span><span class="self">self</span>::token::<span class="kw-2">*</span>;
<a href=#26 id=26 data-nosnippet>26</a>
<a href=#27 id=27 data-nosnippet>27</a><span class="kw">pub</span>(<span class="kw">crate</span>) <span class="kw">mod </span>lexer;
<a href=#28 id=28 data-nosnippet>28</a><span class="kw">pub</span>(<span class="kw">crate</span>) <span class="kw">use </span><span class="self">self</span>::lexer::<span class="kw-2">*</span>;
<a href=#29 id=29 data-nosnippet>29</a>
<a href=#30 id=30 data-nosnippet>30</a><span class="kw">use </span>leo_errors::Result;
<a href=#31 id=31 data-nosnippet>31</a><span class="kw">use </span>leo_span::Span;
<a href=#32 id=32 data-nosnippet>32</a><span class="kw">use </span>std::iter;
<a href=#33 id=33 data-nosnippet>33</a>
<a href=#34 id=34 data-nosnippet>34</a><span class="doccomment">/// Creates a new vector of spanned tokens from a given file path and source code text.
<a href=#35 id=35 data-nosnippet>35</a></span><span class="kw">pub</span>(<span class="kw">crate</span>) <span class="kw">fn </span>tokenize(input: <span class="kw-2">&amp;</span>str, start_pos: u32) -&gt; <span class="prelude-ty">Result</span>&lt;Vec&lt;SpannedToken&gt;&gt; {
<a href=#36 id=36 data-nosnippet>36</a>    tokenize_iter(input, start_pos).collect()
<a href=#37 id=37 data-nosnippet>37</a>}
<a href=#38 id=38 data-nosnippet>38</a>
<a href=#39 id=39 data-nosnippet>39</a><span class="doccomment">/// Yields spanned tokens from the given source code text.
<a href=#40 id=40 data-nosnippet>40</a>///
<a href=#41 id=41 data-nosnippet>41</a>/// The `lo` byte position determines where spans will start.
<a href=#42 id=42 data-nosnippet>42</a></span><span class="kw">pub</span>(<span class="kw">crate</span>) <span class="kw">fn </span>tokenize_iter(<span class="kw-2">mut </span>input: <span class="kw-2">&amp;</span>str, <span class="kw-2">mut </span>lo: u32) -&gt; <span class="kw">impl </span><span class="lifetime">'_ </span>+ Iterator&lt;Item = <span class="prelude-ty">Result</span>&lt;SpannedToken&gt;&gt; {
<a href=#43 id=43 data-nosnippet>43</a>    iter::from_fn(<span class="kw">move </span>|| {
<a href=#44 id=44 data-nosnippet>44</a>        <span class="kw">while </span>!input.is_empty() {
<a href=#45 id=45 data-nosnippet>45</a>            <span class="kw">let </span>(token_len, token) = <span class="kw">match </span>Token::eat(input) {
<a href=#46 id=46 data-nosnippet>46</a>                <span class="prelude-val">Err</span>(e) =&gt; <span class="kw">return </span><span class="prelude-val">Some</span>(<span class="prelude-val">Err</span>(e)),
<a href=#47 id=47 data-nosnippet>47</a>                <span class="prelude-val">Ok</span>(t) =&gt; t,
<a href=#48 id=48 data-nosnippet>48</a>            };
<a href=#49 id=49 data-nosnippet>49</a>            input = <span class="kw-2">&amp;</span>input[token_len..];
<a href=#50 id=50 data-nosnippet>50</a>
<a href=#51 id=51 data-nosnippet>51</a>            <span class="kw">let </span>span = Span::new(lo, lo + token_len <span class="kw">as </span>u32);
<a href=#52 id=52 data-nosnippet>52</a>            lo = span.hi;
<a href=#53 id=53 data-nosnippet>53</a>
<a href=#54 id=54 data-nosnippet>54</a>            <span class="kw">match </span>token {
<a href=#55 id=55 data-nosnippet>55</a>                Token::WhiteSpace =&gt; <span class="kw">continue</span>,
<a href=#56 id=56 data-nosnippet>56</a>                <span class="kw">_ </span>=&gt; <span class="kw">return </span><span class="prelude-val">Some</span>(<span class="prelude-val">Ok</span>(SpannedToken { token, span })),
<a href=#57 id=57 data-nosnippet>57</a>            }
<a href=#58 id=58 data-nosnippet>58</a>        }
<a href=#59 id=59 data-nosnippet>59</a>
<a href=#60 id=60 data-nosnippet>60</a>        <span class="prelude-val">None
<a href=#61 id=61 data-nosnippet>61</a>    </span>})
<a href=#62 id=62 data-nosnippet>62</a>}
<a href=#63 id=63 data-nosnippet>63</a>
<a href=#64 id=64 data-nosnippet>64</a><span class="attr">#[cfg(test)]
<a href=#65 id=65 data-nosnippet>65</a></span><span class="kw">mod </span>tests {
<a href=#66 id=66 data-nosnippet>66</a>    <span class="kw">use super</span>::<span class="kw-2">*</span>;
<a href=#67 id=67 data-nosnippet>67</a>    <span class="kw">use </span>leo_span::{create_session_if_not_set_then, source_map::FileName};
<a href=#68 id=68 data-nosnippet>68</a>    <span class="kw">use </span>std::fmt::Write;
<a href=#69 id=69 data-nosnippet>69</a>
<a href=#70 id=70 data-nosnippet>70</a>    <span class="attr">#[test]
<a href=#71 id=71 data-nosnippet>71</a>    </span><span class="kw">fn </span>test_tokenizer() {
<a href=#72 id=72 data-nosnippet>72</a>        create_session_if_not_set_then(|s| {
<a href=#73 id=73 data-nosnippet>73</a>            <span class="kw">let </span>raw = <span class="string">r#"
<a href=#74 id=74 data-nosnippet>74</a>    "test"
<a href=#75 id=75 data-nosnippet>75</a>    "test{}test"
<a href=#76 id=76 data-nosnippet>76</a>    "test{}"
<a href=#77 id=77 data-nosnippet>77</a>    "{}test"
<a href=#78 id=78 data-nosnippet>78</a>    "test{"
<a href=#79 id=79 data-nosnippet>79</a>    "test}"
<a href=#80 id=80 data-nosnippet>80</a>    "test{test"
<a href=#81 id=81 data-nosnippet>81</a>    "test}test"
<a href=#82 id=82 data-nosnippet>82</a>    "te{{}}"
<a href=#83 id=83 data-nosnippet>83</a>    test_ident
<a href=#84 id=84 data-nosnippet>84</a>    12345
<a href=#85 id=85 data-nosnippet>85</a>    address
<a href=#86 id=86 data-nosnippet>86</a>    as
<a href=#87 id=87 data-nosnippet>87</a>    assert
<a href=#88 id=88 data-nosnippet>88</a>    assert_eq
<a href=#89 id=89 data-nosnippet>89</a>    assert_neq
<a href=#90 id=90 data-nosnippet>90</a>    async
<a href=#91 id=91 data-nosnippet>91</a>    bool
<a href=#92 id=92 data-nosnippet>92</a>    const
<a href=#93 id=93 data-nosnippet>93</a>    else
<a href=#94 id=94 data-nosnippet>94</a>    false
<a href=#95 id=95 data-nosnippet>95</a>    field
<a href=#96 id=96 data-nosnippet>96</a>    for
<a href=#97 id=97 data-nosnippet>97</a>    function
<a href=#98 id=98 data-nosnippet>98</a>    Future
<a href=#99 id=99 data-nosnippet>99</a>    group
<a href=#100 id=100 data-nosnippet>100</a>    i128
<a href=#101 id=101 data-nosnippet>101</a>    i64
<a href=#102 id=102 data-nosnippet>102</a>    i32
<a href=#103 id=103 data-nosnippet>103</a>    i16
<a href=#104 id=104 data-nosnippet>104</a>    i8
<a href=#105 id=105 data-nosnippet>105</a>    if
<a href=#106 id=106 data-nosnippet>106</a>    in
<a href=#107 id=107 data-nosnippet>107</a>    inline
<a href=#108 id=108 data-nosnippet>108</a>    input
<a href=#109 id=109 data-nosnippet>109</a>    let
<a href=#110 id=110 data-nosnippet>110</a>    mut
<a href=#111 id=111 data-nosnippet>111</a>    private
<a href=#112 id=112 data-nosnippet>112</a>    program
<a href=#113 id=113 data-nosnippet>113</a>    public
<a href=#114 id=114 data-nosnippet>114</a>    return
<a href=#115 id=115 data-nosnippet>115</a>    scalar
<a href=#116 id=116 data-nosnippet>116</a>    self
<a href=#117 id=117 data-nosnippet>117</a>    signature
<a href=#118 id=118 data-nosnippet>118</a>    string
<a href=#119 id=119 data-nosnippet>119</a>    struct
<a href=#120 id=120 data-nosnippet>120</a>    test
<a href=#121 id=121 data-nosnippet>121</a>    transition
<a href=#122 id=122 data-nosnippet>122</a>    true
<a href=#123 id=123 data-nosnippet>123</a>    u128
<a href=#124 id=124 data-nosnippet>124</a>    u64
<a href=#125 id=125 data-nosnippet>125</a>    u32
<a href=#126 id=126 data-nosnippet>126</a>    u16
<a href=#127 id=127 data-nosnippet>127</a>    u8
<a href=#128 id=128 data-nosnippet>128</a>    !
<a href=#129 id=129 data-nosnippet>129</a>    !=
<a href=#130 id=130 data-nosnippet>130</a>    &amp;&amp;
<a href=#131 id=131 data-nosnippet>131</a>    (
<a href=#132 id=132 data-nosnippet>132</a>    )
<a href=#133 id=133 data-nosnippet>133</a>    *
<a href=#134 id=134 data-nosnippet>134</a>    **
<a href=#135 id=135 data-nosnippet>135</a>    +
<a href=#136 id=136 data-nosnippet>136</a>    ,
<a href=#137 id=137 data-nosnippet>137</a>    -
<a href=#138 id=138 data-nosnippet>138</a>    -&gt;
<a href=#139 id=139 data-nosnippet>139</a>    =&gt;
<a href=#140 id=140 data-nosnippet>140</a>    _
<a href=#141 id=141 data-nosnippet>141</a>    .
<a href=#142 id=142 data-nosnippet>142</a>    ..
<a href=#143 id=143 data-nosnippet>143</a>    /
<a href=#144 id=144 data-nosnippet>144</a>    :
<a href=#145 id=145 data-nosnippet>145</a>    ;
<a href=#146 id=146 data-nosnippet>146</a>    &lt;
<a href=#147 id=147 data-nosnippet>147</a>    &lt;=
<a href=#148 id=148 data-nosnippet>148</a>    =
<a href=#149 id=149 data-nosnippet>149</a>    ==
<a href=#150 id=150 data-nosnippet>150</a>    &gt;
<a href=#151 id=151 data-nosnippet>151</a>    &gt;=
<a href=#152 id=152 data-nosnippet>152</a>    [
<a href=#153 id=153 data-nosnippet>153</a>    ]
<a href=#154 id=154 data-nosnippet>154</a>    {{
<a href=#155 id=155 data-nosnippet>155</a>    }}
<a href=#156 id=156 data-nosnippet>156</a>    ||
<a href=#157 id=157 data-nosnippet>157</a>    ?
<a href=#158 id=158 data-nosnippet>158</a>    @
<a href=#159 id=159 data-nosnippet>159</a>    // test
<a href=#160 id=160 data-nosnippet>160</a>    /* test */
<a href=#161 id=161 data-nosnippet>161</a>    //"#</span>;
<a href=#162 id=162 data-nosnippet>162</a>            <span class="kw">let </span>sf = s.source_map.new_source(raw, FileName::Custom(<span class="string">"test"</span>.into()));
<a href=#163 id=163 data-nosnippet>163</a>            <span class="kw">let </span>tokens = tokenize(<span class="kw-2">&amp;</span>sf.src, sf.absolute_start).unwrap();
<a href=#164 id=164 data-nosnippet>164</a>            <span class="kw">let </span><span class="kw-2">mut </span>output = String::new();
<a href=#165 id=165 data-nosnippet>165</a>            <span class="kw">for </span>SpannedToken { token, .. } <span class="kw">in </span>tokens.iter() {
<a href=#166 id=166 data-nosnippet>166</a>                <span class="macro">write!</span>(output, <span class="string">"{token} "</span>).expect(<span class="string">"failed to write string"</span>);
<a href=#167 id=167 data-nosnippet>167</a>            }
<a href=#168 id=168 data-nosnippet>168</a>
<a href=#169 id=169 data-nosnippet>169</a>            <span class="macro">assert_eq!</span>(
<a href=#170 id=170 data-nosnippet>170</a>                output,
<a href=#171 id=171 data-nosnippet>171</a>                <span class="string">r#""test" "test{}test" "test{}" "{}test" "test{" "test}" "test{test" "test}test" "te{{}}" test_ident 12345 address as assert assert_eq assert_neq async bool const else false field for function Future group i128 i64 i32 i16 i8 if in inline input let mut private program public return scalar self signature string struct test transition true u128 u64 u32 u16 u8 ! != &amp;&amp; ( ) * ** + , - -&gt; =&gt; _ . .. / : ; &lt; &lt;= = == &gt; &gt;= [ ] { { } } || ? @ // test
<a href=#172 id=172 data-nosnippet>172</a> /* test */ // "#
<a href=#173 id=173 data-nosnippet>173</a>            </span>);
<a href=#174 id=174 data-nosnippet>174</a>        });
<a href=#175 id=175 data-nosnippet>175</a>    }
<a href=#176 id=176 data-nosnippet>176</a>
<a href=#177 id=177 data-nosnippet>177</a>    <span class="attr">#[test]
<a href=#178 id=178 data-nosnippet>178</a>    </span><span class="kw">fn </span>test_spans() {
<a href=#179 id=179 data-nosnippet>179</a>        create_session_if_not_set_then(|s| {
<a href=#180 id=180 data-nosnippet>180</a>            <span class="kw">let </span>raw = <span class="string">r#"
<a href=#181 id=181 data-nosnippet>181</a>ppp            test
<a href=#182 id=182 data-nosnippet>182</a>            // test
<a href=#183 id=183 data-nosnippet>183</a>            test
<a href=#184 id=184 data-nosnippet>184</a>            /* test */
<a href=#185 id=185 data-nosnippet>185</a>            test
<a href=#186 id=186 data-nosnippet>186</a>            /* test
<a href=#187 id=187 data-nosnippet>187</a>            test */
<a href=#188 id=188 data-nosnippet>188</a>            test
<a href=#189 id=189 data-nosnippet>189</a>            "#</span>;
<a href=#190 id=190 data-nosnippet>190</a>
<a href=#191 id=191 data-nosnippet>191</a>            <span class="kw">let </span>sm = <span class="kw-2">&amp;</span>s.source_map;
<a href=#192 id=192 data-nosnippet>192</a>            <span class="kw">let </span>sf = sm.new_source(raw, FileName::Custom(<span class="string">"test"</span>.into()));
<a href=#193 id=193 data-nosnippet>193</a>            <span class="kw">let </span>tokens = tokenize(<span class="kw-2">&amp;</span>sf.src, sf.absolute_start).unwrap();
<a href=#194 id=194 data-nosnippet>194</a>            <span class="kw">let </span><span class="kw-2">mut </span>line_indices = <span class="macro">vec!</span>[<span class="number">0</span>];
<a href=#195 id=195 data-nosnippet>195</a>            <span class="kw">for </span>(i, c) <span class="kw">in </span>raw.chars().enumerate() {
<a href=#196 id=196 data-nosnippet>196</a>                <span class="kw">if </span>c == <span class="string">'\n' </span>{
<a href=#197 id=197 data-nosnippet>197</a>                    line_indices.push(i + <span class="number">1</span>);
<a href=#198 id=198 data-nosnippet>198</a>                }
<a href=#199 id=199 data-nosnippet>199</a>            }
<a href=#200 id=200 data-nosnippet>200</a>            <span class="kw">for </span>token <span class="kw">in </span>tokens.iter() {
<a href=#201 id=201 data-nosnippet>201</a>                <span class="macro">assert_eq!</span>(token.token.to_string(), sm.contents_of_span(token.span).unwrap());
<a href=#202 id=202 data-nosnippet>202</a>            }
<a href=#203 id=203 data-nosnippet>203</a>        })
<a href=#204 id=204 data-nosnippet>204</a>    }
<a href=#205 id=205 data-nosnippet>205</a>}</code></pre></div></section></main></body></html>